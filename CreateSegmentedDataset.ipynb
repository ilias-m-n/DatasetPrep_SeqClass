{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5b47c6-e81e-4369-93d3-a42361c5b4c3",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2fea3c0-a65e-407b-a56d-a8279d09902a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from transformers import (AutoTokenizer,)\n",
    "from datasets import Dataset, DatasetDict, Features, ClassLabel, Value, concatenate_datasets\n",
    "from huggingface_hub import login\n",
    "from collections import Counter\n",
    "\n",
    "import utility.utility as util\n",
    "\n",
    "# Below import and instructions simply for display\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# resets import once changes have been applied\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abc253-37f0-41b2-b76c-b4ca96a258c6",
   "metadata": {},
   "source": [
    "# Directory and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea3f1b00-ad7c-4b79-a884-d8be380721ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cwd = os.getcwd()\n",
    "\n",
    "path_datasets = os.path.join(path_cwd, \"datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dba483-925c-4941-8ddd-56afd0d31890",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e22edea-20fa-4bf8-9824-43d7d3477876",
   "metadata": {},
   "outputs": [],
   "source": [
    "_from_hub = False\n",
    "\n",
    "_dataset_names_hub = [\"Databasesprojec/FinStmts_ConsUncons_English_EU_Predict_part_1\",\n",
    "                      \"Databasesprojec/FinStmts_ConsUncons_English_EU_Predict_part_2\"]\n",
    "\n",
    "_dataset_names_local = [\"test_english_new\"]\n",
    "\n",
    "_col_text = \"text\"\n",
    "_col_id = \"filename\"\n",
    "_col_label = \"label\"\n",
    "\n",
    "_base_model = \"bert-base-multilingual-cased\"\n",
    "\n",
    "_flag_full_seg = True\n",
    "\n",
    "_semi_num_segments = {\"front\":4, \"back\":4}\n",
    "\n",
    "_slide_step_size_perc_of_max = .2\n",
    "\n",
    "paths_local_datasets = [os.path.join(path_datasets, ds) for ds in _dataset_names_local]\n",
    "datasets = _dataset_names_hub if _from_hub else paths_local_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25680617-9a0a-4569-b0ec-55184ce321ed",
   "metadata": {},
   "source": [
    "# Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a90fc8d9-9b01-476c-a11a-95ced57a5a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(_base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f29629-8756-4b0c-9e44-3f82066ec220",
   "metadata": {},
   "source": [
    "# Extract Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c11a005d-be2c-4d7b-8935-6387bdd01038",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_spec_tokens_per_example = util.det_num_spec_tokens(tokenizer)\n",
    "\n",
    "tokens_per_segment = tokenizer.model_max_length - no_spec_tokens_per_example\n",
    "\n",
    "slide_step_size = int(tokens_per_segment * _slide_step_size_perc_of_max)\n",
    "\n",
    "special_token_ids = tokenizer.convert_tokens_to_ids(tokenizer.all_special_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c84df7-bcb9-4663-b3cc-6b8c754506c4",
   "metadata": {},
   "source": [
    "# Segment and Save DatasetDicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98cb3e69-b234-4cf7-b1aa-9ceb8ba40b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['filename', 'text', 'label'],\n",
      "        num_rows: 9987\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['filename', 'text', 'label'],\n",
      "        num_rows: 2134\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['filename', 'text', 'label'],\n",
      "        num_rows: 2138\n",
      "    })\n",
      "})\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                                                                           | 0/9987 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (95517 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9987/9987 [46:12<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2134/2134 [1:16:06<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2138/2138 [07:28<00:00,  4.77it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d4cfcb2d534a7da6cf9766abff579a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/79707 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becc8cdca673416e85265363e313400f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/17041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f304f4342e0c4d6280edd464335e4db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/17064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ds in datasets:\n",
    "    tmp_data = util.load_data(_from_hub, ds, ds)\n",
    "    features = None\n",
    "    for key in tmp_data:\n",
    "        features = tmp_data[key].features\n",
    "        features[\"id\"] = Value(\"string\")\n",
    "        \n",
    "    tmp_data = util.apply_sliding_window_to_datasetdict(tmp_data,\n",
    "                                                        _col_id,\n",
    "                                                        _col_text,\n",
    "                                                        tokenizer, \n",
    "                                                        tokens_per_segment, \n",
    "                                                        special_token_ids,\n",
    "                                                        slide_step_size,\n",
    "                                                        _col_label,\n",
    "                                                        _semi_num_segments,\n",
    "                                                        _flag_full_seg)\n",
    "\n",
    "    tmp_data = util.create_dataset_dict(tmp_data, features)\n",
    "\n",
    "    tmp_data.save_to_disk(ds + \"_segmented_\" + _base_model + (\"_full\" if _flag_full_seg else \"_semi\"))        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml_bert",
   "language": "python",
   "name": "venv_ml_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
