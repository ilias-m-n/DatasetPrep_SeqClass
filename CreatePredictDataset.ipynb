{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141bf640-aae7-45ca-9042-5478846094fe",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb457d87-d9db-49a5-a9a3-d21f4fcbf0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "from collections import Counter\n",
    "from transformers import (AutoTokenizer,)\n",
    "from datasets import Dataset, DatasetDict, Features, ClassLabel, Value, concatenate_datasets\n",
    "from huggingface_hub import login\n",
    "\n",
    "import utility.utility as util\n",
    "\n",
    "# Below import and instructions simply for display\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# resets import once changes have been applied\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91007af7-e9d4-4b3a-b810-81f37edb9e26",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e267ce7-ae09-4a3a-b3d0-38b9537a9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to root directory\n",
    "path_cwd = os.getcwd()\n",
    "\n",
    "# name of folder with raw dataset\n",
    "_name_raw_dataset_dir = \"en_pred\"\n",
    "\n",
    "# name for processed dataset\n",
    "_name_datasetdict = \"test_en_predict\"\n",
    "\n",
    "# path to directory with raw datasets\n",
    "path_raw_dataset = os.path.join(path_cwd, \"raw_data\", _name_raw_dataset_dir)\n",
    "\n",
    "# path to directory with datasetdicts\n",
    "path_processed_dataset = os.path.join(path_cwd, \"datasets\", _name_datasetdict)\n",
    "\n",
    "# columns of interest to keep from meta file\n",
    "_coi = [\"eu\"]\n",
    "\n",
    "# file format to parse - currently not needed, incase different parsing schemes provided\n",
    "_file_format = \".txt\"\n",
    "\n",
    "# create partitions\n",
    "_flag_partition = True\n",
    "# number of partitions\n",
    "_num_partitions = 10\n",
    "\n",
    "# random number generator seed\n",
    "_seed = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56caf486-4439-455c-b68d-5150dc79e30e",
   "metadata": {},
   "source": [
    "# Set file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e915389-b55a-41c8-9a98-5796e2e81318",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = None\n",
    "meta_file = None\n",
    "\n",
    "for item in os.listdir(path_raw_dataset):\n",
    "    if item.endswith(\".csv\"):\n",
    "        meta_file = os.path.join(path_raw_dataset, item)\n",
    "    else:\n",
    "        path_data = os.path.join(path_raw_dataset, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e40174-f50a-4258-b614-4e014c208882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ilias\\\\Desktop\\\\UniMaResearch2023\\\\DatasetPrep\\\\raw_data\\\\en_pred\\\\predict'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ca3fd8-32c1-4eaf-bd38-52053c328ff1",
   "metadata": {},
   "source": [
    "# Parse files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad17f76-e511-413a-b18e-5cbc08c0cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "for item in os.listdir(path_data):\n",
    "    files.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68544ea9-3cd4-464f-8c86-a04f36e8be1a",
   "metadata": {},
   "source": [
    "# Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2be11dcc-8b2e-43d5-b079-ad54ad589d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame()\n",
    "\n",
    "data_df[\"filename\"] = files\n",
    "data_df[\"filepath\"] = data_df.apply(lambda x: os.path.join(path_data, x[\"filename\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a59775-f7d8-486b-8bb0-c434e06ef344",
   "metadata": {},
   "source": [
    "# If present, read meta file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e343d11-3889-4f59-9960-289a4ec661fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = None\n",
    "if meta_file:\n",
    "    meta_df = pd.read_csv(meta_file)\n",
    "    # reduce to coi\n",
    "    meta_df = meta_df[[\"filename\"] + _coi]\n",
    "    meta_df[\"filename\"] = meta_df[\"filename\"].astype(str)\n",
    "    # tell hala to save entire document name\n",
    "    meta_df[\"filename\"] = meta_df[\"filename\"] + \".txt\"\n",
    "    \n",
    "    # Here we limit to only EU files - modify according to needs\n",
    "    meta_df = meta_df[meta_df[\"eu\"] == 1]\n",
    "    meta_df.drop(\"eu\", axis=1, inplace=True)\n",
    "    \n",
    "    data_df = pd.merge(data_df, meta_df, on= \"filename\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2bac78-5319-41a8-8974-4c1ada80433c",
   "metadata": {},
   "source": [
    "# Indexes for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a5c9f6c-0390-4d3e-a2c5-8ea8ddb5fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "if _flag_partition:\n",
    "    indexes = [i/_num_partitions for i in range(_num_partitions+1)]\n",
    "    indexes = [(int(indexes[i] * data_df.shape[0]),int(indexes[i+1] * data_df.shape[0])) for i in range(len(indexes)-1)]\n",
    "else:\n",
    "    indexes = [(0, data_df.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f53ac8-7f91-4c11-9c38-110388cc7b66",
   "metadata": {},
   "source": [
    "# Define Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "756fdb16-7b38-4401-b8c2-02072ece6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Features({\n",
    "    \"filename\": Value(\"string\"),\n",
    "    \"text\": Value(\"string\"),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bf70fb-7536-4536-b2b4-34b2acaa4e65",
   "metadata": {},
   "source": [
    "# Process Partitions and Save to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d4ad956-43c9-482c-b602-1d972cfc6eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0, 5442)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i, index in enumerate(indexes):\n",
    "    print(i, index)\n",
    "    tmp_df = data_df.iloc[index[0]:index[1], :].copy()\n",
    "    tmp_df[\"text\"] = tmp_df[\"filepath\"].apply(util.parse_txt)\n",
    "    \n",
    "    tmp_df.drop(columns=[\"filepath\"], inplace=True)\n",
    "    tmp_df.dropna(subset=[\"text\"], inplace=True)\n",
    "    tmp_df[\"filename\"] = tmp_df[\"filename\"].astype(\"string\")\n",
    "    tmp_df[\"text\"] = tmp_df[\"text\"].astype(\"string\")\n",
    "    tmp_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    tmp_df = Dataset.from_pandas(tmp_df, features)\n",
    "    tmp_df = DatasetDict({\"predict\":tmp_df})\n",
    "\n",
    "    tmp_df.save_to_disk(path_processed_dataset + \"_\" + str(i))\n",
    "\n",
    "    del tmp_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml_bert",
   "language": "python",
   "name": "venv_ml_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
