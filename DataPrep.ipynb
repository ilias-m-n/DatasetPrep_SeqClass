{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3141ea2-283d-4a60-a8a0-1bc8c37927b9",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a06f19b6-0481-4a6d-a614-0687a02fb7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from transformers import (AutoTokenizer,)\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import utility.utility as util\n",
    "\n",
    "# Below import and instructions simply for display\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# resets import once changes have been applied\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eec6a0-0180-42d0-a0ba-00f0e2874800",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73f6ad4-0536-4529-b027-56195e3eba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Labels\n",
    "_labels = {\"cons\": 1, \"uncons\": 0}\n",
    "\n",
    "# langugaes\n",
    "\"\"\"\n",
    "options:\n",
    "    fr: French\n",
    "    de: German\n",
    "    da: Danish\n",
    "\"\"\"\n",
    "_languages = [\"de\"]\n",
    "\n",
    "# columns of interest\n",
    "_coi = [\"filename\", \"language\", \"label\"]\n",
    "\n",
    "# number of instances per class per lang\n",
    "no_inst_lang = {}\n",
    "no_inst_class_lang = {}\n",
    "\n",
    "# data splits sizes\n",
    "_split_sizes = {\"train\": .7, \"validation\": .15, \"test\": .15}\n",
    "# data splits groupby arguments\n",
    "_strat_split_groupby = []\n",
    "\n",
    "# \n",
    "files_per_split_per_label = {}\n",
    "\n",
    "# Random Number Generator seed\n",
    "_seed = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981a56a7-f718-4961-8686-4801e98676fd",
   "metadata": {},
   "source": [
    "# Directory and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a558c6-2db2-4e31-a390-83d61bc5dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "path_data = os.path.join(os.getcwd(), \"raw_data\")\n",
    "paths_data_classes = {}\n",
    "\n",
    "# files\n",
    "paths_meta_files = {}\n",
    "\n",
    "# dataset_dict\n",
    "path_dataset_dict = os.path.join(os.getcwd(), \"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3aa83f6-1e80-4b17-940e-87305cceaca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _class in os.listdir(path_data):\n",
    "    paths_data_classes[_class] = os.path.join(path_data, _class)\n",
    "    for file in os.listdir(paths_data_classes[_class]):\n",
    "        if file.split(\".\")[1] == \"xlsx\":\n",
    "            paths_meta_files[_class] = os.path.join(paths_data_classes[_class], file) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b791dfd-7d27-407c-899e-55d36ac1f102",
   "metadata": {},
   "source": [
    "# Load Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7f95755-e46d-4dbd-b646-b1f4713322a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.DataFrame()\n",
    "meta_per_class = {}\n",
    "\n",
    "def path_join_df(args):\n",
    "    return os.path.join(*args)\n",
    "    \n",
    "\n",
    "for _class in paths_meta_files:\n",
    "    tmp_meta = pd.read_excel(paths_meta_files[_class])\n",
    "    tmp_meta.columns = tmp_meta.columns.str.lower()\n",
    "\n",
    "    # filter for desired languages\n",
    "    tmp_meta = tmp_meta[tmp_meta[\"language\"].isin(_languages)].copy()\n",
    "    \n",
    "    meta_per_class[_class] = tmp_meta\n",
    "    meta_per_class[_class][\"label\"] = _labels[_class]\n",
    "    meta_per_class[_class].drop([col for col in meta_per_class[_class].columns if col not in _coi], axis=1, inplace=True)\n",
    "    \n",
    "    meta_per_class[_class][\"filepath\"] = meta_per_class[_class].apply(lambda x: path_join_df([paths_data_classes[_class], str(x.filename) + \".txt\"]), axis=1)\n",
    "    \n",
    "    \n",
    "    meta = pd.concat([meta, meta_per_class[_class]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e13e9-0a19-46cc-810a-7eb090d0ef7f",
   "metadata": {},
   "source": [
    "## Number of files per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a798c8a-cff5-4ef3-a7e7-eaf995bb00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in _languages:\n",
    "    no_inst_class_lang[lang] = {}\n",
    "    no_inst_lang[lang] = 0\n",
    "    for _class in meta_per_class:\n",
    "        tmp_meta = meta_per_class[_class]\n",
    "        no_inst_class_lang[lang][_class] = tmp_meta[tmp_meta[\"language\"] == lang].shape[0]\n",
    "        no_inst_lang[lang] += no_inst_class_lang[lang][_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "830e00da-f280-4929-8649-1c5328619dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'de': {'cons': 5881, 'uncons': 180}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_inst_class_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46126071-62f2-4f0b-a0cb-f04a5258497c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'de': 6061}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_inst_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cfb436-d7de-40f6-ab9c-aa399d1f2424",
   "metadata": {},
   "source": [
    "# Create splits on file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64cccbf1-27d5-451c-a13e-ed53308bc4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n",
      "{1: {'train': [0, 4117], 'validation': [4117, 4999], 'test': [4999, 5881]}, 0: {'train': [0, 126], 'validation': [126, 153], 'test': [153, 180]}}\n"
     ]
    }
   ],
   "source": [
    "data_splits_meta = {}\n",
    "\n",
    "for lang in _languages:\n",
    "    print(lang)\n",
    "    data_splits_meta[lang] = udp.createStratifiedSplit(meta[meta.language == lang], \"label\", _split_sizes , seed = _seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c6a7a-c42d-43ea-82b5-cb5a3e2e0d57",
   "metadata": {},
   "source": [
    "# Parse Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a204387f-6475-4597-b3b2-ec73c82d1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_txt(file_path):\n",
    "    res = None\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = file.read()\n",
    "            # temporary solution, data should be cleaned before creating datasets\n",
    "            pattern = re.compile(r'\\w+')\n",
    "            if not bool(re.search(pattern, res)):\n",
    "                return None\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ac7e942-9b04-45ae-96e2-ed4b83aff134",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = {}\n",
    "\n",
    "for s in _split_sizes:\n",
    "    data_splits[s] = pd.DataFrame()\n",
    "    for lang in _languages:\n",
    "        data_splits[s] = pd.concat([data_splits[s], data_splits_meta[lang][s][[\"filepath\",\"label\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c9e3973-c3d7-40bd-bf01-8885cf3fecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in data_splits:\n",
    "    data_splits[s][\"text\"] = data_splits[s][\"filepath\"].apply(parse_txt)\n",
    "    data_splits[s].drop(\"filepath\", axis=1, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "402cebb4-be8c-431e-b5f3-d26289937200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove none texts\n",
    "for s in data_splits:\n",
    "    data_splits[s].dropna(subset=[\"text\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb5e2b-18da-470a-b3b6-c77ee9d9c8f2",
   "metadata": {},
   "source": [
    "# Create arrow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c81961-f09e-410f-a7a7-782cfa24237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in data_splits:\n",
    "    data_splits[split] = Dataset.from_pandas(data_splits[split][[\"label\", \"text\"]])\n",
    "    data_splits[split] = data_splits[split].rename_column(\"__index_level_0__\", \"idx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e3e639e-6aaa-4564-a495-7bdfc269469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['label', 'text', 'idx'],\n",
       "     num_rows: 4213\n",
       " }),\n",
       " 'validation': Dataset({\n",
       "     features: ['label', 'text', 'idx'],\n",
       "     num_rows: 904\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['label', 'text', 'idx'],\n",
       "     num_rows: 903\n",
       " })}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb3d4bc-5e12-47b3-860c-71203dcba41c",
   "metadata": {},
   "source": [
    "# Create dataset dictionary for HuggingFace API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f080ad55-ef57-40c4-a667-de2599413830",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict(data_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d90c6f9-8a7d-435c-b30b-b612bb087d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'idx'],\n",
       "        num_rows: 4213\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text', 'idx'],\n",
       "        num_rows: 904\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'idx'],\n",
       "        num_rows: 903\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6484c-f9f8-4b4c-9211-462cc460294a",
   "metadata": {},
   "source": [
    "# Export Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26b7c2df-4d26-4e47-a786-267dad5742ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4628c9741094471d90cd63905311cab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/4213 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3baab5cb41b247aba9a64f229fe3f1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8574c5cde3b9465e985aeab42fafcf9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/903 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dict.save_to_disk(os.path.join(path_dataset_dict, \"German_ConsUncons\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml_bert",
   "language": "python",
   "name": "venv_ml_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
